{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOt5hHRU5rRskt/f4CpEpuR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Change the working directory to the project folder\n","%cd \"/content/drive/MyDrive/directory/dataset\""],"metadata":{"id":"f-wzO-csOhIf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install rdflib --quiet"],"metadata":{"id":"ru9UKQmZUB8C"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Property and class mappings"],"metadata":{"id":"Fes14MDIjaCe"}},{"cell_type":"code","source":["import os\n","import csv\n","import json\n","import rdflib\n","from rdflib import Graph, Namespace, RDF, URIRef\n","from collections import defaultdict\n","\n","extension = False\n","\n","CRM = Namespace(\"http://www.cidoc-crm.org/cidoc-crm/\")\n","WESO_S = Namespace(\"http://weso.es/shapes/\")\n","EX = Namespace(\"http://example.org/\")\n","RDF_NS = Namespace(\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\")\n","\n","class_mappings = {\n","        str(CRM.E53_Place): {\"label\": \"Place\", \"wikibase_id\": \"Q3\"},\n","        str(EX.Occupation): {\"label\": \"Occupation\", \"wikibase_id\": \"Q39\"},\n","        str(CRM.E31_Document): {\"label\": \"Document\", \"wikibase_id\": \"Q30\"},\n","        str(CRM.E74_Group): {\"label\": \"Group\", \"wikibase_id\": \"Q17\"},\n","        str(CRM.E55_Type): {\"label\": \"Type\", \"wikibase_id\": \"Q31\"},\n","        str(CRM.E98_Currency): {\"label\": \"Currency\", \"wikibase_id\": \"Q38\"},\n","        str(CRM.E97_MonetaryAmount): {\"label\": \"Monetary Amount\", \"wikibase_id\": \"Q37\"},\n","        str(EX.PublicOffice): {\"label\": \"Public Office\", \"wikibase_id\": \"Q56\"},\n","        str(CRM.E27_Site): {\"label\": \"Site\", \"wikibase_id\": \"Q27\"},\n","        \"http://www.cidoc-crm.org/cidoc-crm/E52_Time-Span\": {\"label\": \"TimeSpan\", \"wikibase_id\": \"Q2\"},\n","        str(CRM.E21_Person): {\"label\": \"Person\", \"wikibase_id\": \"Q16\"},\n","        str(CRM.E96_Purchase): {\"label\": \"Purchase\", \"wikibase_id\": \"Q14\"},\n","        str(CRM.E8_Acquisition): {\"label\": \"Acquisition\", \"wikibase_id\": \"Q9\"},\n","        str(CRM.E7_Activity): {\"label\": \"Activity\", \"wikibase_id\": \"Q8\"},\n","        str(CRM.E12_Production): {\"label\": \"Production\", \"wikibase_id\": \"Q13\"},\n","        str(CRM.E69_Death): {\"label\": \"Death\", \"wikibase_id\": \"Q35\"},\n","    }\n","\n","property_mappings = {\n","    str(CRM.P1_is_identified_by): \"P1:string\",\n","    str(EX.nativeLabel): \"P69:string\",\n","    str(CRM.P180_has_currency): \"P44:wikibase-item\",\n","    str(CRM.P90_has_value): \"P33:quantity\",\n","    str(EX.applies_to_jurisdiction): \"P64:wikibase-item\",\n","    str(CRM.P53_has_former_or_current_location): \"P27:wikibase-item\",\n","    str(CRM.P82_at_some_time_within): \"P32:time\",\n","    str(EX.givenName): \"P49:wikibase-item\",\n","    str(EX.familyName): \"P50:wikibase-item\",\n","    str(EX.occupation): \"P52:wikibase-item\",\n","    str(EX.spouse): \"P56:wikibase-item\",\n","    str(EX.residence): \"P55:wikibase-item\",\n","    str(EX.child): \"P59:wikibase-item\",\n","    str(EX.father): \"P57:wikibase-item\",\n","    str(EX.position_held): \"P65:wikibase-item\",\n","    str(EX.mother): \"P58:wikibase-item\",\n","    str(EX.sibling): \"P60:wikibase-item\",\n","    str(EX.employer): \"P54:wikibase-item\",\n","    str(EX.work_location): \"P53:wikibase-item\",\n","    str(EX.nickname): \"P51:string\",\n","    str(EX.relative_cousin): \"P61:wikibase-itemPQ62-Cousin\",\n","    str(EX.relative_grandchild): \"P61:wikibase-itemPQ62-Grandchild\",\n","    str(EX.relative_nephew): \"P61:wikibase-itemPQ62-Nephew\",\n","    str(EX.relative_uncle): \"P61:wikibase-itemPQ62-Uncle\",\n","    str(EX.relative_grandfather): \"P61:wikibase-itemPQ62-Grandfather\",\n","    str(EX.relative_grandmother): \"P61:wikibase-itemPQ62-Grandmother\",\n","    \"http://example.org/relative_sibling-in-law\": \"P61:wikibase-itemPQ62-Sibling-in-law\",\n","    \"http://example.org/relative_father-in-law\": \"P61:wikibase-itemPQ62-Father-in-law\",\n","    \"http://example.org/relative_son-in-law\": \"P61:wikibase-itemPQ62-Son-in-law\",\n","    str(EX.regnalOrdinal): \"P66:string\",\n","    str(EX.title): \"P67:string\",\n","    str(CRM.P70i_is_documented_in): \"P28:wikibase-item\",\n","    \"http://www.cidoc-crm.org/cidoc-crm/P4_has_time-span\": \"P6:wikibase-item\",\n","    str(CRM.P2_has_type): \"P5:wikibase-item\",\n","    str(CRM.P179_had_sales_price): \"P43:wikibase-item\",\n","    str(CRM.P24_transferred_title_of): \"P19:wikibase-item\",\n","    str(CRM.P23_transferred_title_from): \"P18:wikibase-item\",\n","    str(CRM.P22_transferred_title_to): \"P17:wikibase-item\",\n","    str(CRM.P14_carried_out_by): \"P12:wikibase-itemPQ13-Witness\",\n","    \"http://www.cidoc-crm.org/cidoc-crm/P14_carried_out_byPQ14.1-Notary\": \"P12:wikibase-itemPQ13-Notary\",\n","    \"http://www.cidoc-crm.org/cidoc-crm/P14_carried_out_byPQ14.1-Judge\": \"P12:wikibase-itemPQ13-Judge\",\n","    \"http://www.cidoc-crm.org/cidoc-crm/P14_carried_out_byPQ14.1-PartyA\": \"P12:wikibase-itemPQ13-PartyA\",\n","    \"http://www.cidoc-crm.org/cidoc-crm/P14_carried_out_byPQ14.1-PartyB\": \"P12:wikibase-itemPQ13-PartyB\",\n","    str(CRM.P17_was_motivated_by): \"P15:wikibase-item\",\n","    str(CRM.P108_has_produced): \"P37:wikibase-item\",\n","    str(CRM.P100_died_in): \"P35:wikibase-item\",\n","    str(CRM.P183_ends_before_the_start_of): \"P46:wikibase-item\",\n","}"],"metadata":{"id":"LVQQK6kzjMoW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# RDF dataset parsing and graph creation"],"metadata":{"id":"ix-SaQ3ljrS1"}},{"cell_type":"code","source":["directory_path = \"./\"\n","output_csv_path = \"../wikibase_import_dataset1.csv\"\n","mapping_output_path = \"../id_mapping.json\"\n","\n","all_data = Graph()\n","\n","for filename in os.listdir(directory_path):\n","        if filename.endswith('.ttl'):\n","            file_path = os.path.join(directory_path, filename)\n","            all_data.parse(file_path, format='turtle')\n","\n","entities_by_p1  = defaultdict(list)\n","places_by_id = {}\n","groups_by_p1 = defaultdict(list)\n","\n","# Dictionary to map original IDs to consolidated entity info\n","id_mapping = {}\n"],"metadata":{"id":"lHjdZdKLjeTV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Preprocessing\n","Change the document-level IDs of Occupations and Public Office to a consolidated, identifiable value."],"metadata":{"id":"ZqiyGNTjkFuF"}},{"cell_type":"code","source":["for s in all_data.subjects():\n","        entity_types = list(all_data.objects(s, RDF.type))\n","\n","        for entity_type in entity_types:\n","            if str(entity_type) == str(EX.Occupation) or str(entity_type) == str(EX.PublicOffice):\n","                entity_id = str(s).split('/')[-1]\n","\n","                # Get P1 values (identifiers)\n","                p1_values = []\n","                for o in all_data.objects(s, CRM.P1_is_identified_by):\n","                    p1_values.append(str(o))\n","\n","                if p1_values:\n","                    # Use the first P1 value as the key for consolidation\n","                    p1_key_original = p1_values[0]\n","                    p1_key_lower = p1_key_original.lower()\n","                    entities_by_p1[p1_key_lower].append({\n","                        \"original_id\": entity_id,\n","                        \"type\": str(entity_type),\n","                        \"p1_values\": p1_values,\n","                        \"original_p1\": p1_key_original\n","                    })\n","\n","            elif str(entity_type) == str(CRM.E53_Place):\n","                entity_id = str(s).split('/')[-1]\n","\n","                # Get P1 values (identifiers)\n","                p1_values = []\n","                for o in all_data.objects(s, CRM.P1_is_identified_by):\n","                    p1_values.append(str(o))\n","\n","                # Store the place with its entity ID and P1 values\n","                places_by_id[entity_id] = {\n","                    \"type\": str(entity_type),\n","                    \"p1_values\": p1_values,\n","                    \"original_id\": entity_id\n","                }\n","            elif str(entity_type) == str(CRM.E74_Group):\n","              entity_id = str(s).split('/')[-1]\n","\n","              # Get P1 values (identifiers)\n","              p1_values = []\n","              for o in all_data.objects(s, CRM.P1_is_identified_by):\n","                  p1_values.append(str(o))\n","\n","              if p1_values:\n","                # Use the first P1 value as the key for consolidation\n","                p1_key_original = p1_values[0]\n","                p1_key_lower = p1_key_original.lower()\n","                groups_by_p1[p1_key_lower].append({\n","                    \"original_id\": entity_id,\n","                    \"type\": str(entity_type),\n","                    \"p1_values\": p1_values,\n","                    \"entity_uri\": s,\n","                    \"original_p1\": p1_key_original\n","                })\n","              else:\n","                  # Si no tiene P1, usar el ID original\n","                  groups_by_p1[entity_id] = {\n","                      \"type\": str(entity_type),\n","                      \"p1_values\": [],\n","                      \"entity_uri\": s,\n","                      \"original_id\": entity_id\n","                  }\n"],"metadata":{"id":"YdUygrinkBxW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Consolidation of document-level persons."],"metadata":{"id":"C-38El0ukWE9"}},{"cell_type":"code","source":["persons_by_id = defaultdict(dict)\n","\n","# First pass: group Person entities by their person ID (Pxxx)\n","for s in all_data.subjects():\n","    entity_types = list(all_data.objects(s, RDF.type))\n","\n","    for entity_type in entity_types:\n","        if str(entity_type) == str(CRM.E21_Person):  # Process Person entities\n","            full_entity_id = str(s).split('/')[-1]\n","\n","            # Extract document and person IDs\n","            if 'P' in full_entity_id:\n","                # Handle special case for DxPBx format\n","                if 'PB' in full_entity_id:\n","                    # Treat as separate entity (no consolidation)\n","                    doc_id = full_entity_id.split('P')[0]\n","                    person_id = full_entity_id\n","                else:\n","                    # Regular case: DxxxPyyy format\n","                    doc_id = full_entity_id.split('P')[0]\n","                    person_id = 'P' + full_entity_id.split('P')[1]\n","\n","                # Initialize or update person record\n","                if person_id not in persons_by_id:\n","                    persons_by_id[person_id] = {\n","                        \"documents\": set(),\n","                        \"properties\": defaultdict(set),\n","                        \"original_ids\": set()\n","                    }\n","\n","                # Add document reference and original ID\n","                persons_by_id[person_id][\"documents\"].add(doc_id)\n","                persons_by_id[person_id][\"original_ids\"].add(full_entity_id)\n","\n","                # Collect all properties for this person\n","                for p, o in all_data.predicate_objects(s):\n","                    if str(p) in property_mappings:\n","                        # Convert URIRef objects to string IDs\n","                        if isinstance(o, URIRef):\n","                            o_val = str(o).split('/')[-1]\n","                        else:\n","                            o_val = str(o)\n","                        persons_by_id[person_id][\"properties\"][str(p)].add(o_val)"],"metadata":{"id":"wYmS9_IlkUJu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Processing\n","## Occupations and Public Offices"],"metadata":{"id":"a0CbaVHBkjy-"}},{"cell_type":"code","source":["csv_rows = []\n","\n","# Process consolidated Occupations\n","for p1_key_lower, entity_group in entities_by_p1.items():\n","    # All entities in this group have the same P1, consolidate them\n","    entity_type = entity_group[0][\"type\"]  # Use type from first entity (should be Occupation)\n","    class_info = class_mappings[entity_type]\n","    p1_display = entity_group[0][\"original_p1\"]\n","    native_label = p1_display\n","    if extension: # Store documents of native label\n","      all_labels = set()\n","      for i in range(len(entity_group)):\n","        all_labels.add(f\"{entity_group[i]['original_id'].split('O')[0]}-{native_label}\") #D1-Oriz, D2-Oriz...\n","      native_label =  \"|\".join(all_labels)\n","\n","    all_ids = set()\n","    for i in range(len(entity_group)):\n","      all_ids.add(f\"AMSPO-{entity_group[i]['original_id']}\")\n","    # Create a consolidated entity row\n","    entity_row = {\n","        \"Item Label\": p1_display,  # Use P1 value as label\n","        \"Description\": f\"Instance of {class_info['label']}\",\n","        \"instance of\": class_info[\"wikibase_id\"],\n","        \"P1:string\": \"|\".join(all_ids),\n","        \"P69:string\": native_label\n","    }\n","\n","    for entity_info in entity_group:\n","        entity_id = entity_info[\"original_id\"]\n","        entity_uri = URIRef(f\"http://example.org/{entity_id}\")\n","\n","        # Collect all properties for this entity\n","        for prop_uri, prop_id in property_mappings.items():\n","            if prop_id not in entity_row:  # Initialize if not already present\n","                entity_row[prop_id] = \"\"\n","\n","            if prop_id == \"P1:string\":\n","                continue\n","\n","            values = []\n","            for o in all_data.objects(entity_uri, URIRef(prop_uri)):\n","                if isinstance(o, URIRef):\n","                    ref_id = str(o).split('/')[-1]\n","                    # Check if this reference is to a consolidated entity\n","                    if ref_id in id_mapping:\n","                        # Use the consolidated label instead\n","                        ref_id = id_mapping[ref_id][\"wikibase_label\"]\n","                    values.append(ref_id)\n","                else:\n","                    # This is a literal value\n","                    values.append(str(o))\n","\n","            # Add values if any found (don't overwrite existing values)\n","            if values:\n","                existing = set(entity_row[prop_id].split(\"|\")) if entity_row[prop_id] else set()\n","                existing.update(values)\n","                # Remove empty string if present\n","                if \"\" in existing:\n","                    existing.remove(\"\")\n","                entity_row[prop_id] = \"|\".join(existing)\n","\n","    csv_rows.append(entity_row)\n","\n","    # Update the mapping for all original IDs in this group\n","    for entity_info in entity_group:\n","        id_mapping[entity_info[\"original_id\"]] = {\n","            \"wikibase_label\": p1_display,\n","            \"p1_value\": p1_display,\n","            \"entity_type\": entity_info[\"type\"]\n","        }"],"metadata":{"id":"-7gJesr0kfD3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Places"],"metadata":{"id":"gy7t71blkvfl"}},{"cell_type":"code","source":["for entity_id, place_info in places_by_id.items():\n","      class_info = class_mappings[place_info[\"type\"]]\n","\n","      # For places, use entity_id as P1 and the P1 value as the label (interchange)\n","      p1_value = entity_id\n","\n","      # Use the first P1 value as the label if available, otherwise use entity_id\n","      if place_info[\"p1_values\"]:\n","          label = place_info[\"p1_values\"][0]\n","      else:\n","          label = entity_id\n","\n","      # Create a row for this place entity\n","      entity_row = {\n","          \"Item Label\": label,  # Use P1 value as label\n","          \"Description\": f\"Instance of {class_info['label']}\",\n","          \"instance of\": class_info[\"wikibase_id\"],\n","          \"P1:string\": p1_value,\n","          \"P69:string\": label\n","      }\n","\n","      csv_rows.append(entity_row)\n","\n","      # Update the mapping for this place entity\n","      id_mapping[entity_id] = {\n","          \"wikibase_label\": label,\n","          \"p1_value\": p1_value,\n","          \"entity_type\": place_info[\"type\"]\n","      }"],"metadata":{"id":"L2ENM5bJk1yy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Process groups by P1\n","for p1_key, entities in groups_by_p1.items():\n","    if not entities:\n","        continue\n","\n","    first_entity = entities[0]\n","    # Create a new consolidated entity\n","    group_row = {\n","        \"Item Label\": first_entity[\"original_p1\"] ,\n","        \"Description\": \"Group\",\n","        \"instance of\": class_mappings[str(CRM.E74_Group)][\"wikibase_id\"]\n","    }\n","\n","\n","    # Añadir un nuevo P1 que sea la combinación de los IDs originales\n","    if \"P1:string\" in property_mappings.values():\n","        # Encuentra la clave para P1\n","        p1_prop_id = next(prop_id for prop_uri, prop_id in property_mappings.items() if prop_id == \"P1:string\")\n","        # Asigna los IDs originales como valor de P1\n","        group_row[p1_prop_id] = \"|\".join(sorted(set(e[\"original_id\"] for e in entities)))\n","\n","\n","    # Collect all properties from all entities with this P1\n","    for entity_info in entities:\n","        entity_id = entity_info[\"original_id\"]\n","        entity_uri = entity_info[\"entity_uri\"]\n","\n","        # Map this entity ID to the consolidated label\n","        id_mapping[entity_id] = {\n","            \"wikibase_label\": entity_info[\"original_p1\"],\n","            \"entity_type\": entity_info[\"type\"]\n","        }\n","\n","        # Add property values\n","        for prop_uri, prop_id in property_mappings.items():\n","            # Saltamos P1 porque ya lo hemos establecido\n","            if prop_id == \"P1:string\":\n","                continue\n","\n","            values = []\n","            uri_references = []\n","\n","            for o in all_data.objects(entity_uri, URIRef(prop_uri)):\n","                if isinstance(o, URIRef):\n","                    # This is a reference to another entity\n","                    ref_id = str(o).split('/')[-1]\n","                    uri_references.append(ref_id)\n","                else:\n","                    # This is a literal value\n","                    values.append(str(o))\n","\n","            # Combine all values\n","            all_values = values + uri_references\n","            if all_values:\n","                # Get existing values if any\n","                existing_values = set()\n","                if prop_id in group_row and group_row[prop_id]:\n","                    existing_values = set(group_row[prop_id].split(\"|\"))\n","\n","                # Add new values\n","                existing_values.update(all_values)\n","\n","                # Update property\n","                group_row[prop_id] = \"|\".join(existing_values)\n","\n","    # Add to CSV rows\n","    csv_rows.append(group_row)"],"metadata":{"id":"kzg3qXJkB-gh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Rest of the classes"],"metadata":{"id":"s28HYo6M--wB"}},{"cell_type":"code","source":["for clase in class_mappings:\n","    if (str(clase) == str(EX.Occupation) or\n","        str(clase) == str(EX.PublicOffice) or\n","        str(clase) == str(CRM.E53_Place) or\n","        str(clase) == str(CRM.E74_Group) or\n","        str(clase) == str(CRM.E21_Person)):\n","        continue\n","\n","    # Dictionary to collect entities by label for this class\n","    entities_by_label = {}\n","\n","    for s in all_data.subjects():\n","        entity_types = list(all_data.objects(s, RDF.type))\n","\n","        for entity_type in entity_types:\n","            if str(entity_type) == str(clase):\n","                entity_id = str(s).split('/')[-1]\n","                class_info = class_mappings[str(entity_type)]\n","\n","                # Get label - use entity_id as label\n","                label = entity_id\n","\n","                if str(entity_type) in [str(CRM.E27_Site), str(CRM.E97_MonetaryAmount), str(CRM.E96_Purchase), str(CRM.E8_Acquisition), str(CRM.E7_Activity), str(CRM.E12_Production)]:\n","                    # Get P1 values (identifiers\n","                    label = f\"AMSPO-{label}\"\n","\n","                # Check if we already have an entity with this label\n","                if label in entities_by_label:\n","                    # Merge properties with existing entity\n","                    existing_row = entities_by_label[label]\n","\n","                    # Add property values to the existing entity\n","                    for prop_uri, prop_id in property_mappings.items():\n","                        values = []\n","                        uri_references = []\n","\n","                        for o in all_data.objects(s, URIRef(prop_uri)):\n","                            if isinstance(o, URIRef):\n","                                # This is a reference to another entity\n","                                ref_id = str(o).split('/')[-1]\n","\n","                                # Check if this reference is to a consolidated entity\n","                                if ref_id in id_mapping and prop_id != \"P27:wikibase-item\":\n","                                    # Use the consolidated label instead\n","                                    ref_id = id_mapping[ref_id][\"wikibase_label\"]\n","\n","                                uri_references.append(ref_id)\n","                            else:\n","                                # This is a literal value\n","                                values.append(str(o))\n","\n","                        # Combine all values\n","                        all_values = values + uri_references\n","                        if all_values:\n","                            # Get existing values if any\n","                            existing_values = set()\n","                            if prop_id in existing_row and existing_row[prop_id]:\n","                                existing_values = set(existing_row[prop_id].split(\"|\"))\n","\n","                            # Add new values\n","                            existing_values.update(all_values)\n","\n","                            # Update property\n","                            existing_row[prop_id] = \"|\".join(existing_values)\n","\n","                    # Update mapping for this entity ID\n","                    id_mapping[entity_id] = {\n","                        \"wikibase_label\": label,\n","                        \"entity_type\": str(entity_type)\n","                    }\n","                else:\n","                    if str(entity_type) == str(CRM.E69_Death):\n","                      entity_row = {\n","                        \"Item Label\": f\"Death before the start of AMSPO-{label.split('Death')[0]} ({label.split('_')[1]})\",\n","                        \"Description\": f\"Instance of {class_info['label']}\",\n","                        \"instance of\": class_info[\"wikibase_id\"],\n","                        \"P1:string\": label\n","                      }\n","                    else:\n","                      entity_row = {\n","                          \"Item Label\": label,\n","                          \"Description\": f\"Instance of {class_info['label']}\",\n","                          \"instance of\": class_info[\"wikibase_id\"]\n","                      }\n","\n","                    # Add property values\n","                    for prop_uri, prop_id in property_mappings.items():\n","                        values = []\n","                        uri_references = []\n","\n","                        for o in all_data.objects(s, URIRef(prop_uri)):\n","                            if isinstance(o, URIRef):\n","                                # This is a reference to another entity\n","                                ref_id = str(o).split('/')[-1]\n","\n","                                # Check if this reference is to a consolidated entity\n","                                if ref_id in id_mapping and prop_id != \"P27:wikibase-item\":\n","                                    # Use the consolidated label instead\n","                                    ref_id = id_mapping[ref_id][\"wikibase_label\"]\n","\n","                                uri_references.append(ref_id)\n","                            else:\n","                                # This is a literal value\n","                                values.append(str(o))\n","\n","                        # Combine all values\n","                        all_values = values + uri_references\n","                        if all_values:\n","                            entity_row[prop_id] = \"|\".join(all_values)\n","                        elif not (str(entity_type) == str(CRM.E69_Death) and prop_id == \"P1:string\"):\n","                            entity_row[prop_id] = \"\"\n","\n","                    # Store entity in our dictionary\n","                    entities_by_label[label] = entity_row\n","\n","                    # Add to mapping\n","                    id_mapping[entity_id] = {\n","                        \"wikibase_label\": label,\n","                        \"entity_type\": str(entity_type)\n","                    }\n","\n","    # Convert dictionary to list and sort\n","    entities_rows = list(entities_by_label.values())\n","\n","    # Sort entities for this class alphabetically and add to csv_rows\n","    if entities_rows:  # Only process if we found entities\n","        sorted_rows = sorted(entities_rows, key=lambda x: x[\"Item Label\"].lower())\n","        csv_rows.extend(sorted_rows)\n"],"metadata":{"id":"lu4mOSCFmDuE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Given name and family name"],"metadata":{"id":"9fON2mJQlAt_"}},{"cell_type":"code","source":["if not extension:\n","  given_names = set()\n","  family_names = set()\n","\n","  # Collect all unique given names and family names from persons\n","  for person_id, person_data in persons_by_id.items():\n","      # Get given name if available\n","      if str(EX.givenName) in person_data[\"properties\"]:\n","          for name in person_data[\"properties\"][str(EX.givenName)]:\n","              given_names.add(name)\n","\n","      # Get family name if available\n","      if str(EX.familyName) in person_data[\"properties\"]:\n","          for name in person_data[\"properties\"][str(EX.familyName)]:\n","              family_names.add(name)\n","\n","  # Create entities for given names (Q53)\n","  for name in given_names:\n","      if name:  # Skip empty names\n","          entity_row = {\n","              \"Item Label\": name,\n","              \"Description\": \"Given name\",\n","              \"instance of\": \"Q53\",  # Given name\n","              \"P69:string\": name,\n","              \"alias\": f\"{name} (given name)\"\n","          }\n","          csv_rows.append(entity_row)\n","\n","          # Add to mapping in case we need to reference it\n","          id_mapping[f\"GivenName_{name}\"] = {\n","              \"wikibase_label\": name,\n","              \"p1_value\": name,\n","              \"entity_type\": \"GivenName\"\n","          }\n","\n","  # Create entities for family names (Q54)\n","  for name in family_names:\n","      if name:  # Skip empty names\n","          entity_row = {\n","              \"Item Label\": name,\n","              \"Description\": \"Family name\",\n","              \"instance of\": \"Q54\",  # Family name\n","              \"P69:string\": name,\n","              \"alias\": f\"{name} (family name)\"\n","          }\n","          csv_rows.append(entity_row)\n","\n","          # Add to mapping in case we need to reference it\n","          id_mapping[f\"FamilyName_{name}\"] = {\n","              \"wikibase_label\": name,\n","              \"p1_value\": name,\n","              \"entity_type\": \"FamilyName\"\n","          }"],"metadata":{"id":"_rpi_YBxlFee"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Person"],"metadata":{"id":"gAZ8PBwolMO1"}},{"cell_type":"code","source":["for person_id, person_data in persons_by_id.items():\n","    # Create label from given name and family name if available\n","    given_name = next(iter(person_data[\"properties\"].get(str(EX.givenName), [\"\"])))\n","    family_name = next(iter(person_data[\"properties\"].get(str(EX.familyName), [\"\"])))\n","    title = next(iter(person_data[\"properties\"].get(str(EX.title), [\"\"])))\n","\n","    if given_name and family_name:\n","        label = f\"{given_name} {family_name}\"\n","    elif given_name and title:\n","        label = f\"{title} {given_name}\"\n","    elif given_name:\n","        label = given_name\n","    else:\n","        label = person_id  # Fallback to person ID\n","\n","    # Create a consolidated entity row\n","    entity_row = {\n","        \"Item Label\": label,\n","        \"Description\": f\"{label} ({person_id} in AMSPO FSV)\",\n","        \"instance of\": class_mappings[str(CRM.E21_Person)][\"wikibase_id\"],\n","        \"P1:string\": f\"AMSPO-{person_id}\",\n","        \"alias\": f\"AMSPO-{person_id}\"\n","    }\n","\n","    # Track which original entity IDs have which property values for residence and work_location\n","    refs_by_doc  = defaultdict(lambda: defaultdict(set))\n","\n","    # First, collect residence and work_location values for each document\n","    for original_id in person_data[\"original_ids\"]:\n","        entity_uri = URIRef(f\"http://example.org/{original_id}\")\n","\n","        # Extract document ID from original entity ID\n","        if 'P' in original_id:\n","            doc_id = original_id.split('P')[0]\n","        else:\n","            doc_id = \"\"  # Fallback\n","\n","        # Collect residence values\n","        for o in all_data.objects(entity_uri, URIRef(str(EX.residence))):\n","            if isinstance(o, URIRef):\n","                ref_id = str(o).split('/')[-1]\n","                refs_by_doc [doc_id][str(EX.residence)].add(ref_id)\n","\n","        # Collect work_location values\n","        for o in all_data.objects(entity_uri, URIRef(str(EX.work_location))):\n","            if isinstance(o, URIRef):\n","                ref_id = str(o).split('/')[-1]\n","                refs_by_doc [doc_id][str(EX.work_location)].add(ref_id)\n","\n","        for o in all_data.objects(entity_uri, URIRef(str(EX.nickname))):\n","            refs_by_doc[doc_id][str(EX.nickname)].add(str(o))\n","\n","        if extension:\n","            for o in all_data.objects(entity_uri, URIRef(str(EX.givenName))):\n","                refs_by_doc[doc_id][str(EX.givenName)].add(str(o))\n","\n","            for o in all_data.objects(entity_uri, URIRef(str(EX.familyName))):\n","                refs_by_doc[doc_id][str(EX.familyName)].add(str(o))\n","\n","    # Add all collected properties\n","    for prop_uri, values in person_data[\"properties\"].items():\n","        if prop_uri in property_mappings:\n","            prop_id = property_mappings[prop_uri]\n","\n","            # Handle occupation and position_held properties\n","            if prop_uri == str(EX.occupation) or prop_uri == str(EX.position_held):\n","                modified_values = set()\n","                for value in values:\n","                    # Extract document ID from the value itself (D125Oc3 format)\n","                    if 'Oc' in value and (prop_uri == str(EX.occupation) or prop_uri == str(EX.position_held)):\n","                        doc_id = value.split('Oc')[0]\n","                        if value in id_mapping:\n","                            entity_value = id_mapping[value][\"p1_value\"]\n","                            modified_values.add(f\"{doc_id}-{entity_value}\")\n","                        else:\n","                            modified_values.add(value)\n","                    else:\n","                        modified_values.add(value)\n","\n","                entity_row[prop_id] = \"|\".join(modified_values)\n","\n","            # Handle residence and work_location properties\n","            elif prop_uri in [str(EX.residence), str(EX.work_location), str(EX.nickname)]:\n","                modified_values = set()\n","\n","                # For each document where this property exists\n","                for doc_id, props in refs_by_doc.items():\n","                    if prop_uri in props:\n","                        # For each value in this document\n","                        for value in props[prop_uri]:\n","                            # For residence and work_location, look up the entity label\n","\n","                            modified_values.add(f\"{doc_id}-{value}\")\n","\n","                entity_row[prop_id] = \"|\".join(modified_values)\n","\n","            elif prop_uri in [str(EX.givenName), str(EX.familyName)]:\n","                modified_values = set()\n","                for value in values:\n","                  if extension:\n","                    for doc_id, props in refs_by_doc.items():\n","                      if prop_uri in props:\n","                          for value in props[prop_uri]:\n","                              modified_values.add(f\"{doc_id}-{value}\")\n","                  else:\n","                    if prop_uri == str(EX.givenName):\n","                      modified_values.add(f\"{value} (given name)\")\n","                    else:\n","                      modified_values.add(f\"{value} (family name)\")\n","                entity_row[prop_id] = \"|\".join(modified_values)\n","\n","            # Handle all other properties normally\n","            else:\n","                entity_row[prop_id] = \"|\".join(values)\n","\n","    # Add document references using P28\n","    if person_data[\"documents\"]:\n","        entity_row[\"P28:wikibase-item\"] = \"|\".join(person_data[\"documents\"])\n","\n","    csv_rows.append(entity_row)\n","\n","    # Update the mapping for all original IDs\n","    for original_id in person_data[\"original_ids\"]:\n","        id_mapping[original_id] = {\n","            \"wikibase_label\": label,\n","            \"person_id\": person_id,\n","            \"entity_type\": str(CRM.E21_Person)\n","        }"],"metadata":{"id":"QWU4lu0nlPPX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Write to file"],"metadata":{"id":"CVLJ1WgMlUP1"}},{"cell_type":"code","source":["with open(output_csv_path, 'w', newline='', encoding='latin-1') as csvfile:\n","    # Create fieldnames\n","    fieldnames = [\"Item Label\", \"Description\", \"alias\", \"instance of\"] + list(property_mappings.values())\n","\n","    writer = csv.DictWriter(csvfile, fieldnames=fieldnames, delimiter=';')\n","    writer.writeheader()\n","\n","    # Write all rows\n","    for row in csv_rows:\n","        writer.writerow(row)\n","\n","# Write the ID mapping to a JSON file\n","with open(mapping_output_path, 'w', encoding='latin-1') as mapping_file:\n","    json.dump(id_mapping, mapping_file, indent=2)\n","\n","print(f\"CSV file created at {output_csv_path}\")\n","print(f\"ID mapping created at {mapping_output_path}\")\n","print(f\"Consolidated {sum(len(group) for group in entities_by_p1.values())} Occupation entities into {len(entities_by_p1)} unique entities\")\n","print(f\"Processed {len(csv_rows)} total entities\")"],"metadata":{"id":"fKj3x1vwTVZu"},"execution_count":null,"outputs":[]}]}